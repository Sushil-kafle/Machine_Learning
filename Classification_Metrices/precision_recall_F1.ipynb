{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precision and recall\n",
    "calculating Precision and Recall from a confusion matrix\n",
    "\n",
    "1. Precision:\n",
    "\n",
    "\n",
    "$$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "\n",
    "where:\n",
    "- **TP (True Positive):** The number of correctly predicted positive samples.\n",
    "- **FP (False Positive):** The number of negative samples incorrectly predicted as positive.\n",
    "\n",
    "2. Recall (Sensitivity or True Positive Rate):\n",
    "\n",
    "\n",
    "$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "where:\n",
    "- **FN (False Negative):** The number of positive samples incorrectly predicted as negative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-score\n",
    "calculate the F1 score from a confusion matrix\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **Precision:** The proportion of correctly predicted positive samples among all samples predicted as positive.\n",
    "- **Recall:** The proportion of correctly predicted positive samples among all actual positive samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weighted\n",
    "Weighted Average:\n",
    "\n",
    "In the context of a multi-class classification problem, the weighted average considers the class-wise metrics (precision, recall, F1 score) and computes their average, weighted by the number of samples in each class.\n",
    "\n",
    "To calculate the weighted average precision, recall, and F1 score:\n",
    "\n",
    "1. Weighted Precision:\n",
    "\n",
    "$$\n",
    "\\text{Weighted Precision} = \\frac{\\sum_{i=1}^{N} \\text{Precision}_i \\times \\text{Support}_i}{\\sum_{i=1}^{N} \\text{Support}_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\text{Precision}_i\\): Precision of class \\(i\\).\n",
    "- \\(\\text{Support}_i\\): Number of samples of class \\(i\\).\n",
    "\n",
    "2. Weighted Recall:\n",
    "\n",
    "$$\n",
    "\\text{Weighted Recall} = \\frac{\\sum_{i=1}^{N} \\text{Recall}_i \\times \\text{Support}_i}{\\sum_{i=1}^{N} \\text{Support}_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\text{Recall}_i\\): Recall of class \\(i\\).\n",
    "- \\(\\text{Support}_i\\): Number of samples of class \\(i\\).\n",
    "\n",
    "3. Weighted F1 Score:\n",
    "\n",
    "$$\n",
    "\\text{Weighted F1 Score} = \\frac{\\sum_{i=1}^{N} \\text{F1 Score}_i \\times \\text{Support}_i}{\\sum_{i=1}^{N} \\text{Support}_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $$ \\text{F1 Score}_i: F1 score of class (i). $$\n",
    "- $$ \\text{Support}_i: Number of samples of class( i). $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Average:\n",
    "\n",
    "The macro average computes the class-wise metrics (precision, recall, F1 score) independently and then takes their unweighted mean to get the macro average.\n",
    "\n",
    "To calculate the macro average precision, recall, and F1 score:\n",
    "\n",
    "1. Macro Precision:\n",
    "\n",
    "$$\n",
    "\\text{Macro Precision} = \\frac{\\sum_{i=1}^{N} \\text{Precision}_i}{N}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- Precision_i: Precision of class i.\n",
    "- N: Total number of classes.\n",
    "\n",
    "2. Macro Recall:\n",
    "\n",
    "$$\n",
    "\\text{Macro Recall} = \\frac{\\sum_{i=1}^{N} \\text{Recall}_i}{N}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- Recall_i: Recall of class i.\n",
    "- N: Total number of classes.\n",
    "\n",
    "3. Macro F1 Score:\n",
    "\n",
    "$$\n",
    "\\text{Macro F1 Score} = \\frac{\\sum_{i=1}^{N} \\text{F1 Score}_i}{N}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- F1 Score_i: F1 score of class i.\n",
    "- N: Total number of classes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
